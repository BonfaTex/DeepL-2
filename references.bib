@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group UK London}
}
@article{guan2019vgg16,
    author = {Guan, Q. and Wang, Y. and Ping, B. and Li, D. and Du, J. and Qin, Y. and Lu, H. and Wan, X. and Xiang, J.},
    title = {Deep convolutional neural network VGG-16 model for differential diagnosing of papillary thyroid carcinomas in cytological images: a pilot study},
    journal = {J Cancer},
    year = {2019},
    volume = {10},
    number = {20},
    pages = {4876-4882}
}
@article{acevedo2019bloodcells,
    author = {Acevedo, Andrea and Alférez, Santiago and Merino, Anna and Puigví, Laura and Rodellar, José},
    title = {Recognition of peripheral blood cell images using convolutional neural networks},
    journal = {Computer Methods and Programs in Biomedicine},
    year = {2019},
    volume = {180},
    pages = {105020},
    issn = {0169-2607},
    doi = {10.1016/j.cmpb.2019.105020},
    url = {https://www.sciencedirect.com/science/article/pii/S0169260719303578}
}
@article{outliers,
    author = {Hamid Ghorbani},
    title = {MAHALANOBIS DISTANCE AND ITS APPLICATION FOR DETECTING MULTIVARIATE OUTLIERS},
    journal = {Facta Universitatis Ser. Math. Inform.},
    year ={2019},
    volume = {34},
    url ={https://casopisi.junis.ni.ac.rs/index.php/FUMathInf/article/view/5028/pdf}
}
@article{oversampling,
    author = {Shorten, C. and Khoshgoftaar, T.M.},
    title = { A survey on Image Data Augmentation for Deep Learning},
    journal = {Journal of Big Data},
    volume ={6},
    year = {2019},
    URL = {https://link.springer.com/article/10.1186/s40537-019-0197-0#citeas}
}
@ARTICLE{mixed-precision,
  author={Dörrich, Marion and Fan, Mingcheng and Kist, Andreas M.},
  journal={IEEE Access}, 
  title={Impact of Mixed Precision Techniques on Training and Inference Efficiency of Deep Neural Networks}, 
  year={2023},
  volume={11},
  number={},
  pages={57627-57634},
  doi={10.1109/ACCESS.2023.3284388},
    url = {https://ieeexplore.ieee.org/abstract/document/10146255}}

@unpublished{overfitting,
  author = "M. Matteucci",
  title  = "Facing Overfitting Lecture",
  month  = "October",
  year   = "2024",
  annote = "A good practice for designing neural networks: train a model that overfits the data. This ensures the model has enough complexity (e.g. sufficient layers, neurons, and parameters) to solve the problem effectively. At this stage, generalization is not the focus: it’s about verifying that the model is capable of fitting the training data. Once overfitting is confirmed, techniques like early stopping and dropout layers are introduced to prevent overfitting and improve generalization to unseen data."
}

@unpublished{aug,
  author = "lukewood",
  title  = "CutMix, MixUp, and RandAugment image augmentation with KerasCV",
  note   = "Online available at \url{https://keras.io/guides/keras_cv/cut_mix_mix_up_and_rand_augment
}",
  month  = "April",
  year   = "2022",
  annote = "A good practice for designing neural networks: train a model that overfits the data. This ensures the model has enough complexity (e.g. sufficient layers, neurons, and parameters) to solve the problem effectively. At this stage, generalization is not the focus: it’s about verifying that the model is capable of fitting the training data. Once overfitting is confirmed, techniques like early stopping and dropout layers are introduced to prevent overfitting and improve generalization to unseen data."
}

@misc{lion,
  author       = {{TensorFlow Developers}},
  title        = {Lion Optimizer},
  year         = {2024},
  note         = {\url{https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Lion}}
}
